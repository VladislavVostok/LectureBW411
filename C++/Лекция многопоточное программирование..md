
1. **Джефф Элджер.** C++: Библиотека программиста. _Основной учебник по продвинутому освоению языка C++._
2. **Марк Дж. Рочкинд.** Программирование для Unix. Must have!
3. **Уильям Ричард Стивенс.** Unix: Взаимодействие процессов. _Учебник по межпроцессному взаимодействию._
4. **Уильям Ричард Стивенс.** Unix: Разработка сетевых приложений. Учебник по работе с сетью.


## Процесс и поток

Основным понятием в любой операционной системе является _процесс_: абстракция, описывающая выполняющуюся программу. Процессы — это одна из самых старых и наиболее важных абстракций, присущих операционной системе. 

Процесс — это просто экземпляр выполняемой программы, включая текущие значения счетчика команд, регистров и переменных.

Для реализации модели процессов операционная система ведет таблицу (состоящую из массива структур), называемую _таблицей процессов_, в которой каждая запись соответствует какому-нибудь процессу. (Ряд авторов называют эти записи _блоками управления процессом_ — _Process Control Block_ — _PCB_.) Эти записи содержат важную информацию о состоянии процесса, включая счетчик команд, указатель стека, распределение памяти, состояние открытых им файлов, его учетную и планировочную информацию и все остальное, касающееся процесса, что должно быть сохранено, когда процесс переключается из состояния выполнения в состояние готовности или блокировки, чтобы позже он мог возобновить выполнение, как будто никогда не останавливался. 

В традиционных операционных системах у каждого процесса есть адресное пространство и единственный поток управления. Фактически это почти что определение процесса. Тем не менее нередко возникают ситуации, когда неплохо было бы иметь в одном и том же адресном пространстве несколько потоков управления, выполняемых _квазипараллельно_, как будто они являются чуть ли не обособленными процессами (за исключением общего адресного пространства). В следующих разделах будут рассмотрены именно такие ситуации и их применение.

Таненбаум называет выполнение процессов _квазипараллельным_ в рамках _одноядерных однопроцессных_ систем. Пример квазипараллельного выполнения изображен на рисунке 2.

![[602d4e8273cad043047295650eee379b_MD5.png]]

Рисунок 2 — Пример квазипараллельного параллелизма на примере двух процессов

Переключение процессора с выполнения одного процесса на выполнение другого называют переключением контекста. Стоит заметить, что время, затраченное на переключение контекста, не используется ОС для совершения полезной работы и является «накладными» расходами, снижающими производительность системы.

В любой многозадачной системе центральный процессор быстро переключается между процессами, предоставляя каждому из них десятки или сотни миллисекунд. При этом хотя в каждый конкретный момент времени центральный процессор работает только с одним процессом, в течение 1 секунды он может успеть поработать с несколькими из них, создавая иллюзию параллельной работы. Иногда в этом случае говорят о _псевдопараллелизме_ в отличие от настоящего аппаратного _параллелизма_ в многопроцессорных системах (у которых имеется не менее двух центральных процессоров, использующих одну и ту же физическую память). 

Выполнение задач на многоядерном процессоре обычно считается истинным параллелизмом. В отличие от _псевдопараллелизма_, который создаёт _иллюзию параллельной работы_ на одноядерном процессоре за счёт быстрого переключения между задачами, многоядерные процессоры могут выполнять несколько задач одновременно, фактически используя разные ядра для разных потоков или процессов. Пример выполнения разных процессов на многопроцессорной системе представлен на рисунке 3.

За распределения процессорного времени отвечает _планировщик ОС_ — компонент ядра, задача которого заключается в обеспечении максимально эффективного использования процессорных ресурсов и справедливого распределения вычислительной мощности.

![[02acbc077784f097ce383abb46f323c2_MD5.png]]

Рисунок 3 — Пример выполнения разных процессов на многопроцессорной системе

Для простоты на рисунке 3 изображены два «абстрактных» одноядерных процессора (желтый и синий) и три «абстрактных» процесса, один из которых имеет два потока. На данном рисунке стоит обратить внимание, что один поток может выполняться на разных процессорах (в зависимости от решений планировщика). Можно заметить, что у третьего процесса могут возникать две возможные ситуации: оба потока выполняются параллельно на разных процессорах или выполняются квазипараллельно на одном.

**Примечание**: на рисунке 3 и далее два процессора можно заменить двумя ядрами одного процессора и на данном уровне абстракции рисунок не поменяется.

Достоинства потоков по сравнению с процессами:

- потоки сильно проще создавать и уничтожать по сравнению с более тяжеловесными процессами;
- единое адресное пространство памяти позволяет ускорить обмен данных избегая межпроцессного общения.

## Применение многопоточности

Рассмотрим следующие подходы к использованию многопоточности:

- разделение вычислений и пользовательского интерфейса — выделяется отдельный поток для обработки пользовательских взаимодействий, в то время как другие потоки занимаются выполнением вычислений (позволяет повысить отзывчивость интерфейса независимо от нагрузки вычислений);
- асинхронные операции ввода-вывода: операции чтения/записи файлов, сетевого взаимодействия или обращений к базам данных выполняются в отдельных потоках (позволяет не блокировать основной поток в ожидании выполнения этих операций);
- параллельная обработка данных — разделение большого объема данных на части, которые будут обработаны параллельно;
- адаптивное распределение работы — задачи приложения являются простыми и распределяются между свободными потоками (пример: несколько работников, проверяющих брак на конвейере).

Данные подходы не являются абсолютными и могут образовывать гибриды, оптимально подходящие для конкретных задач приложения.

## Стандартизация многопоточности

Институт инженеров электротехники и электроники (IEEE — Institute of Electrical and Electronics Engineers) в 1995 году определил стандарт IEEE standard 1003.1c — Portable Operating System Interface (POSIX), в рамках которого присутствовал пакет, касающийся потоков Pthreads. Данный стандарт поддерживается в большинстве UNIX-систем включая Linux и Mac OS. Использование pthreads в ОС семейства Windows требует использования библиотеки _Pthreads-win32_ или компилятора _MinGW_ с флагом _-lpthread_. 

Стандарт C++11 ввел в язык C++ стандартизированную поддержку многопоточности, включая потоки (threads), мьютексы (mutexes), условные переменные (condition variables) и атомарные операции. Это значительно упростило разработку многопоточных приложений на C++, делая код более переносимым между различными платформами. Библиотека Boost также содержит модули, описывающие работу с многопоточностью. _Boost.Thread_ — часть библиотеки Boost, предлагает расширенные возможности для многопоточного программирования в C++.

В операционных системах семейства Windows существует набор интерфейсов WinAPI, который включает в себя инструменты для работы с потоками. Многопоточность стала доступна в рамках серверной версии Windows NT в 1993. С использовании потоков в WinAPI можно ознакомиться в [источнике](https://learn.microsoft.com/ru-ru/windows/win32/procthread/about-processes-and-threads) . Так же в экосистеме .NET (включая C#, F# и VB.NET) многопоточность поддерживается через классы, находящиеся в пространстве имен _System.Threading_, предоставляя разнообразные возможности для создания и управления потоками, а также для синхронизации работы между ними.

## Возможные проблемы в многопоточных приложениях

Многопоточные приложения, хотя и предлагают значительные преимущества в плане производительности и эффективности использования ресурсов, также связаны с рядом потенциальных проблем и сложностей, связанных с параллельным выполнением кода.

Многопоточные приложения требуют тщательного проектирования, чтобы избежать сложности управления состоянием и обеспечить эффективную работу с ресурсами. Неправильное проектирование может затруднить масштабирование и поддержку приложения.

### Состояние гонки (Race condition)

Гонка данных возникает, когда два или более потоков одновременно пытаются изменить общие данные, и результат выполнения зависит от того, какой поток получит доступ первым. Это может привести к некорректному состоянию данных. Пример данной проблемы изображен на рисунке 4.

![[991fc35dd08dfe4fcace305820f2da40_MD5.png]]

Рисунок 4 — Пример состояния гонки

На рисунке 4 представлены две ситуации: состояние гонки на двухпроцессорной (слева) и однопроцессорной (справа) системах. Здесь указан простой высокоуровневый пример, но стоит учитывать, что проблема гонки на запись ресурсов может возникать даже с простыми операциями на уровне переноса данных из регистров процессоров: такая ситуация изображена на рисунке 5.

![[66eafe79a87bfbe06e4745378fe58322_MD5.png]]

Рисунок 5 — Пример состояния гонки на уровне работы с регистрами

В качестве решения можно использовать механизмы блокировки, такие как мьютексы или семафоры, для обеспечения взаимоисключающего доступа к общим ресурсам.

### Взаимная блокировка (Deadlock)

Взаимная блокировка возникает, когда два или более потоков ожидают друг друга для освобождения ресурсов, уже занятых ими, в результате чего все ожидающие потоки оказываются заблокированными и не могут продолжить выполнение. Проблема deadlock’a изображена на рисунке 6.

![[ee27d3417eeeeead87724d4d63eca6b7_MD5.png]]

Рисунок 6 — Проблема взаимной блокировки

Для избежания таких ситуаций можно:

- применять иерархии блокировок, при которой все потоки захватывают блокировки в одном и том же порядке;
- использование тайм-аутов для блокировок;
- обнаружение и восстановление после взаимной блокировки.

### Живые блокировки (Livelocks)

Живая блокировка возникает, когда два или более потоков активно реагируют на действия друг друга таким образом, что они продолжают изменять состояние без возможности продвижения вперёд. Причина зачастую кроется в реализации алгоритмов управления доступом к ресурсам или в ошибках в логике состояния приложения. Она может быть вызвана некорректным дизайном системы синхронизации, когда потоки постоянно пытаются избежать взаимной блокировки, активно меняя свои состояния, что приводит к бесконечному циклу.

Рассмотрим простой пример живой блокировки на примере задачи, где муж и жена пытаются поужинать, но между ними только одна ложка. Каждый из супругов вежлив и передает ложку, если другой еще не ел. Блок-схема и поведение потоков в случае живой блокировки изображены на рисунке 7.

![[e0ebc8bdb6cec0b6de12adc16e7c8b68_MD5.png]]

Рисунок 7 — Проблема живых блокировок на примере задачи с вежливыми супругами

**Важное замечание**: если в задаче не отправлять поток в сон — будет максимальная нагрузка на процессор (ядро).



### Голодание (Starvation)

Голодание происходит, когда один или несколько потоков не могут получить доступ к необходимым ресурсам в течение длительного времени из-за постоянного занятия этих ресурсов другими потоками.

Настройка приоритетов потоков позволяет выделять больше процессорного времени для «обделяемых» потоков.


### Трудности отладки и тестирования

Многопоточные приложения сложнее отлаживать и тестировать, поскольку проблемы могут воспроизводиться нестабильно и зависеть от конкретной последовательности выполнения потоков, что затрудняет диагностику и устранение ошибок.

### Мьютексы (Mutexes)

Мьютексы предоставляют механизм блокировки, который позволяет потокам последовательно получать доступ к общему ресурсу. Когда поток захватывает мьютекс, другие потоки не могут получить доступ к защищенному им ресурсу до тех пор, пока первый поток не освободит мьютекс.

### Семафоры (Semaphores)

Семафоры позволяют контролировать доступ к общим ресурсам, ограничивая количество потоков, которые могут одновременно использовать ресурс. Семафоры характеризуются счётчиком, который уменьшается, когда поток захватывает семафор, и увеличивается, когда поток освобождает его.

### Условные переменные (Condition Variables)

Условные переменные используются для блокировки потока до наступления определённого условия. Они обычно используются в сочетании с мьютексами для ожидания изменения состояния приложения, при этом поток, ожидающий условия, не занимает ресурсы процессора.

### Барьеры (Barriers)

Барьеры синхронизируют группу потоков в определённой точке программы. Все потоки должны достичь барьера, прежде чем любой из них сможет продолжить выполнение. Это полезно для координации фаз в параллельных алгоритмах.

### Атомарные операции

Атомарные операции гарантируют, что комплексные операции (например, инкремент, декремент, сравнение и обмен) выполняются неделимо. Это позволяет потокам безопасно изменять общие данные без использования тяжеловесных механизмов блокировки.

### Блокировка чтения-записи (RW-lock)

RW-lock (блокировка чтения-записи, блокировка «много читателей, один писатель») – это примитив синхронизации, который позволяет решить проблему «читателей-писателя». Проблема «много читателей, один писатель» довольно часто встречается при решении практических задач многопоточного программирования. Такая проблема появляется тогда, когда много потоков читают данные, и один поток пишет (изменяет) данные. Простой подход с использованием мьютекса считается медленным, так как нет необходимости блокировать ресурс, когда его только читают. Pthreads решает эту проблему с помощью блокировки чтения-записи, которая обеспечивает множественный доступ потоков читателей, и эксклюзивный доступ потока писателя.


# Многопоточное программирование на C++


Многопоточное программирование позволяет выполнять несколько задач одновременно, что особенно важно в современных многоядерных процессорах. В C++ поддержка многопоточности была значительно улучшена с стандартом C++11 и продолжает развиваться.

## Основные темы многопоточного программирования в C++

### 1. Потоки Нити (Threads)

Базовый механизм создания и управления потоками.

#### Что такое потоки?

Потоки (threads) — это наименьшие единицы выполнения в программе, которые могут выполняться параллельно в рамках одного процесса. В отличие от процессов, которые имеют отдельные адресные пространства, потоки одного процесса разделяют общую память и ресурсы, но имеют собственные стеки вызовов и регистры процессора.

#### Зачем использовать потоки?

1. **Повышение производительности**: На многоядерных процессорах потоки позволяют распределить работу между ядрами.
2. **Отзывчивость интерфейса**: Главный поток может обрабатывать пользовательский ввод, а фоновые потоки выполнять тяжелые вычисления.
3. **Параллельная обработка задач**: Одновременное выполнение независимых операций (например, загрузка данных и их обработка).
4. **Эффективное использование ресурсов**: Пока один поток ожидает ввода-вывода, другие могут продолжать работу.

#### Основные концепции потоков в C++

##### 1. Создание потока

```cpp
#include <iostream>
#include <thread>

using namespace std;
// Функция, которая будет выполняться в потоке
void threadFunction() {
    cout << "Привет из нового потока!\n";
}

int main() {
    // Создаем поток, передавая ему функцию для выполнения
    thread t(threadFunction);

    // Ждем завершения потока
    t.join();

    cout << "Привет из главного потока!\n";
    return 0;
}
```

##### 2. Передача аргументов в поток

```cpp
#include <iostream>
#include <thread>
#include <string>

void printMessage(const std::string& message, int count) {
    for (int i = 0; i < count; ++i) {
        std::cout << message << " (" << i+1 << "/" << count << ")\n";
    }
}

int main() {
    // Создаем поток с аргументами
    std::thread t(printMessage, "Сообщение из потока", 5);
    
    t.join();
    return 0;
}
```
##### 3. Пример с несколькими потоками

```cpp
#include <iostream>
#include <thread>
#include <vector>
#include <chrono>

void worker(int id) {
    std::cout << "Поток " << id << " начал работу\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(100 * id));
    std::cout << "Поток " << id << " завершил работу\n";
}

int main() {
    const int num_threads = 5;
    std::vector<std::thread> threads;
    
    // Создаем несколько потоков
    for (int i = 0; i < num_threads; ++i) {
        threads.emplace_back(worker, i+1);
    }
    
    // Ожидаем завершения всех потоков
    for (auto& t : threads) {
        t.join();
    }
    
    std::cout << "Все потоки завершили работу\n";
    return 0;
}

```
#### Методы класса std::thread

Рассмотрим подробнее важные методы класса std::thread с примерами их использования.

- **join()**: Ожидает завершения потока **(уже ознакомились)**
- **detach()**: Отсоединяет поток (поток продолжает работать самостоятельно)
- **joinable()**: Проверяет, можно ли присоединиться к потоку
- **get_id()**: Возвращает идентификатор потока
- **hardware_concurrency()**: Возвращает количество поддерживаемых аппаратных потоков


##### 1. detach() - отсоединение потока

Позволяет потоку работать независимо от создавшего его потока. После вызова detach() поток продолжает выполнение самостоятельно.

```cpp
#include <iostream>
#include <thread>
#include <chrono>

void independentThread() {
    std::cout << "Отсоединенный поток начал работу\n";
    std::this_thread::sleep_for(std::chrono::seconds(2));
    std::cout << "Отсоединенный поток завершил работу\n";
}

int main() {
    std::thread t(independentThread);
    
    // Отсоединяем поток - main() может завершиться раньше, чем поток
    t.detach();
    
    // Проверяем, что поток действительно отсоединен
    if (t.joinable()) {
        t.join(); // Этот код не выполнится
    } else {
        std::cout << "Поток отсоединен\n";
    }
    
    // Ждем, чтобы увидеть вывод отсоединенного потока
    std::this_thread::sleep_for(std::chrono::seconds(3));
    
    return 0;
}
```

Метод `detach()` класса `std::thread` служит для отсоединения потока от объекта `std::thread`, позволяя потоку продолжать выполнение независимо от создавшего его потока.

###### ==Основное назначение `detach()`==

1. **Автономное выполнение потока**:
   - После вызова `detach()` поток продолжает работать самостоятельно
   - Объект `std::thread` больше не управляет этим потоком
   - Поток завершится автоматически при завершении программы

2. **Когда используется**:
   - Для фоновых задач, которые должны работать независимо от основного потока
   - Когда не нужно ждать завершения потока
   - Для демонических процессов (daemon threads)

###### ==Пример использования `detach()`==

```cpp
#include <iostream>
#include <thread>
#include <chrono>

void backgroundTask() {
    for (int i = 0; i < 5; ++i) {
        std::cout << "Фоновая задача выполняется... " << i << std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
    std::cout << "Фоновая задача завершена" << std::endl;
}

int main() {
    std::thread worker(backgroundTask);
    
    // Отсоединяем поток - он продолжит работу независимо от main()
    worker.detach();
    
    // Главный поток продолжает работу
    std::cout << "Главный поток работает..." << std::endl;
    std::this_thread::sleep_for(std::chrono::seconds(2));
    
    std::cout << "Главный поток завершается" << std::endl;
    // При завершении программы фоновый поток будет автоматически остановлен
    return 0;
}
```

###### ==Важные особенности `detach()`==

1. **Потеря контроля**:
   - После `detach()` вы не можете:
     - Проверить статус потока
     - Дождаться его завершения (`join()`)
     - Получить результат работы

2. **Условия использования**:
   - Можно вызывать только для joinable-потоков
   - После вызова `detach()` объект `std::thread` становится не joinable

```cpp
std::thread t(someFunction);

if (t.joinable()) {
    t.detach(); // Корректно
}

t.detach(); // Ошибка, если поток уже не joinable
```

3. **Проблемы доступа к данным**:
   - Отсоединенные потоки могут обращаться к данным, которые уже были уничтожены
   - Особенно опасно при работе с локальными переменными

###### ==Типичные сценарии использования==

1. **Логирование в фоне**:
```cpp
void asyncLog(const std::string& message) {
    std::thread([message]() {
        // Имитация записи в лог
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
        std::cout << "LOG: " << message << std::endl;
    }).detach(); // Сразу отсоединяем
}
```

2. **Периодические фоновые задачи**:
```cpp
void startBackgroundService() {
    std::thread([]() {
        while (true) {
            performServiceTask();
            std::this_thread::sleep_for(std::chrono::minutes(1));
        }
    }).detach();
}
```

3. **Обработка сетевых соединений**:
```cpp
void handleConnection(int socket) {
    std::thread([socket]() {
        // Обработка соединения
        processClient(socket);
        close(socket);
    }).detach();
}
```

###### ==Опасности и лучшие практики==

1. **Проблема висящих ссылок**:
```cpp
void dangerousDetach() {
    int localVar = 42;
    
    std::thread([&localVar]() {
        std::this_thread::sleep_for(std::chrono::seconds(1));
        std::cout << localVar << std::endl; // Неопределенное поведение!
    }).detach();
    
    // Функция завершается, localVar уничтожается,
    // но поток пытается получить к нему доступ
}
```

2. **Решение - передача по значению**:
```cpp
void safeDetach() {
    int localVar = 42;
    
    std::thread([localVar]() { // Копируем значение
        std::this_thread::sleep_for(std::chrono::seconds(1));
        std::cout << localVar << std::endl; // Безопасно
    }).detach();
}
```

3. **Использование shared_ptr для сложных объектов**:
```cpp
void safeObjectDetach() {
    auto data = std::make_shared<MyData>(...);
    
    std::thread([data]() { // Захватываем shared_ptr
        processData(data);
    }).detach();
}
```

###### Альтернативы `detach()`

1. **Использование `join()` с контролем времени**:
```cpp
std::thread t(longTask);

// Ждем не более 100ms
if (t.joinable()) {
    t.join_for(std::chrono::milliseconds(100));
    if (t.joinable()) {
        t.detach(); // Если не завершился - отсоединяем
    }
}
```

2. **Пул потоков** (лучшее решение для большинства случаев):
```cpp
ThreadPool pool(4);
pool.enqueueTask(backgroundTask); // Не требует detach()
```

###### Вывод

`detach()` полезен для:
- Долго работающих фоновых задач
- Операций, результат которых не важен для основного потока
- Сценариев, где невозможно использовать `join()`

Но требует особой осторожности:
- С контролем времени жизни данных
- С управлением ресурсами
- С обработкой ошибок

В современных приложениях часто лучше использовать:
- Пул потоков
- Асинхронные операции (std::async)
- Высокоуровневые параллельные алгоритмы


##### 2. joinable() - проверка возможности присоединения

Проверяет, можно ли вызвать join() или detach() для потока.

```cpp
#include <iostream>
#include <thread>

void threadFunction() {
    std::cout << "Работа потока\n";
}

int main() {
    std::thread t;
    
    std::cout << "Перед созданием: joinable = " << t.joinable() << "\n";
    
    t = std::thread(threadFunction);
    std::cout << "После создания: joinable = " << t.joinable() << "\n";
    
    if (t.joinable()) {
        t.join();
    }
    
    std::cout << "После join: joinable = " << t.joinable() << "\n";
    
    return 0;
}
```

##### 3. get_id() - получение идентификатора потока

Возвращает уникальный идентификатор потока.

```cpp
#include <iostream>
#include <thread>
#include <vector>

void worker() {
    std::cout << "Поток с ID: " << std::this_thread::get_id() << " работает\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
}

int main() {
    const int num_threads = 5;
    std::vector<std::thread> threads;
    
    // Создаем и запускаем потоки
    for (int i = 0; i < num_threads; ++i) {
        threads.emplace_back(worker);
    }
    
    // Выводим ID главного потока
    std::cout << "Главный поток ID: " << std::this_thread::get_id() << "\n";
    
    // Выводим ID созданных потоков
    for (auto& t : threads) {
        std::cout << "Созданный поток ID: " << t.get_id() << "\n";
        t.join();
    }
    
    // ID несуществующего потока
    std::thread t;
    std::cout << "ID неинициализированного потока: " << t.get_id() << "\n";
    
    return 0;
}
```

##### 4. hardware_concurrency() - количество аппаратных потоков

Возвращает количество потоков, которые могут быть действительно выполнены параллельно.

```cpp
#include <iostream>
#include <thread>
#include <vector>

void task(int id) {
    std::cout << "Задача " << id << " выполняется на ядре "
              << std::this_thread::get_id() << "\n";
    // Имитация работы
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
}

int main() {
    // Получаем количество поддерживаемых аппаратных потоков
    unsigned int n = std::thread::hardware_concurrency();
    
    std::cout << "Доступно аппаратных потоков: " << n << "\n";
    
    // Создаем оптимальное количество потоков
    std::vector<std::thread> threads;
    for (unsigned int i = 0; i < n; ++i) {
        threads.emplace_back(task, i+1);
    }
    
    for (auto& t : threads) {
        t.join();
    }
    
    // Пример, когда hardware_concurrency() не может определить количество
    if (n == 0) {
        std::cout << "Не удалось определить количество ядер. Используем 2 потока.\n";
        std::thread t1(task, 1);
        std::thread t2(task, 2);
        t1.join();
        t2.join();
    }
    
    return 0;
}
```

##### 5. Комбинированный пример использования всех методов

```cpp
#include <iostream>
#include <thread>
#include <chrono>

void printThreadInfo(const std::string& thread_name) {
    std::cout << thread_name << " ID: " << std::this_thread::get_id() << "\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(500));
}

int main() {
    std::cout << "Количество аппаратных потоков: " 
              << std::thread::hardware_concurrency() << "\n\n";
    
    std::thread t1(printThreadInfo, "Поток 1");
    std::thread t2;
    
    std::cout << "Поток 1 joinable: " << t1.joinable() << "\n";
    std::cout << "Поток 2 joinable: " << t2.joinable() << "\n\n";
    
    if (t1.joinable()) {
        std::cout << "Присоединяем поток 1...\n";
        t1.join();
    }
    
    t2 = std::thread(printThreadInfo, "Поток 2");
    
    std::cout << "Отсоединяем поток 2...\n";
    t2.detach();
    
    // Небольшая задержка, чтобы увидеть вывод отсоединенного потока
    std::this_thread::sleep_for(std::chrono::seconds(1));
    
    std::cout << "\nГлавный поток завершает работу\n";
    return 0;
}
```

#### Важные замечания

1. После вызова `detach()` вы теряете контроль над потоком - он будет завершен при завершении программы.
2. `joinable()` возвращает `false` для:
   - Неинициализированных потоков
   - Потоков, которые уже были присоединены (join) или отсоединены (detach)
   - Потоков, которые были перемещены в другой объект потока
3. `get_id()` возвращает `std::thread::id()` для неинициализированных потоков.
4. `hardware_concurrency()` может вернуть 0, если не может определить количество ядер.
5. **Гонка данных (Race conditions)**: Когда несколько потоков обращаются к общим данным без синхронизации.
6. **Взаимоблокировки (Deadlocks)**: Когда потоки блокируют друг друга, ожидая ресурсы.
7. **Исключения в потоках**: Неперехваченные исключения в потоках приводят к вызову std::terminate().


### 2. Мьютексы (Mutexes)

Механизмы синхронизации для защиты общих данных.

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <vector>

std::mutex mtx; // Мьютекс для синхронизации доступа
int shared_data = 0;

void increment(int n) {
    for (int i = 0; i < n; ++i) {
        // Блокируем мьютекс перед доступом к общим данным
        std::lock_guard<std::mutex> lock(mtx);
        ++shared_data;
        // Мьютекс автоматически освобождается при выходе из области видимости
    }
}

int main() {
    std::thread t1(increment, 100000);
    std::thread t2(increment, 100000);
    
    t1.join();
    t2.join();
    
    std::cout << "Результат: " << shared_data << std::endl;
    // Без мьютекса результат мог бы быть меньше 200000
    return 0;
}
```


Мьютексы (mutex - mutual exclusion) - это базовый механизм синхронизации потоков, предназначенный для защиты общих данных от одновременного доступа. Рассмотрим их подробно.

#### Основные типы мьютексов в C++

##### 1. std::mutex - базовый мьютекс

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::mutex mtx; // Создаем мьютекс
int shared_data = 0;

void increment() {
    for (int i = 0; i < 100000; ++i) {
        mtx.lock();   // Блокируем мьютекс
        ++shared_data; // Критическая секция
        mtx.unlock(); // Разблокируем мьютекс
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);
    
    t1.join();
    t2.join();
    
    std::cout << "Результат: " << shared_data << std::endl;
    return 0;
}
```

##### 2. std::lock_guard - RAII-обертка для мьютекса

Автоматически освобождает мьютекс при выходе из области видимости.

```cpp
void safer_increment() {
    for (int i = 0; i < 100000; ++i) {
        std::lock_guard<std::mutex> lock(mtx); // Блокировка при создании
        ++shared_data; // Автоматическая разблокировка при разрушении lock
    }
}
```

##### 3. std::unique_lock - более гибкая RAII-обертка

Позволяет откладывать блокировку и управлять ей вручную.

```cpp
void flexible_increment() {
    for (int i = 0; i < 100000; ++i) {
        std::unique_lock<std::mutex> lock(mtx, std::defer_lock); // Не блокируем сразу
        // Можно выполнить другие операции...
        lock.lock(); // Блокируем явно
        ++shared_data;
        // Можно разблокировать раньше конца области видимости
        lock.unlock();
    }
}
```

##### 4. std::recursive_mutex - рекурсивный мьютекс

Позволяет одному потоку многократно блокировать один и тот же мьютекс.

```cpp
std::recursive_mutex rec_mtx;

void recursive_function(int level) {
    std::lock_guard<std::recursive_mutex> lock(rec_mtx);
    std::cout << "Уровень: " << level << std::endl;
    
    if (level > 0) {
        recursive_function(level - 1);
    }
}
```

##### 5. std::timed_mutex - мьютекс с таймаутом

Позволяет пытаться заблокировать мьютекс в течение ограниченного времени.

```cpp
std::timed_mutex timed_mtx;

void timed_thread() {
    auto now = std::chrono::steady_clock::now();
    if (timed_mtx.try_lock_until(now + std::chrono::milliseconds(100))) {
        std::cout << "Поток получил блокировку\n";
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        timed_mtx.unlock();
    } else {
        std::cout << "Поток не получил блокировку за отведенное время\n";
    }
}
```

#### Безопасные шаблоны использования мьютексов

##### 1. Защита доступа к общим данным

```cpp
class ThreadSafeCounter {
private:
    mutable std::mutex mtx;
    int value = 0;

public:
    void increment() {
        std::lock_guard<std::mutex> lock(mtx);
        ++value;
    }
    
    int get() const {
        std::lock_guard<std::mutex> lock(mtx);
        return value;
    }
};
```

##### 2. Двойная проверка блокировки (Double-Checked Locking)

Оптимизация для редких случаев изменения данных.

```cpp
class Singleton {
private:
    static Singleton* instance;
    static std::mutex mtx;
    
    Singleton() {}
    
public:
    static Singleton* getInstance() {
        if (!instance) { // Первая проверка без блокировки
            std::lock_guard<std::mutex> lock(mtx);
            if (!instance) { // Вторая проверка с блокировкой
                instance = new Singleton();
            }
        }
        return instance;
    }
};
```

##### 3. Защита нескольких ресурсов

```cpp
class BankAccount {
    std::mutex mtx;
    double balance;
public:
    void transfer(BankAccount& to, double amount) {
        // Чтобы избежать deadlock, блокируем оба мьютекса в фиксированном порядке
        std::lock(mtx, to.mtx); // Блокируем оба мьютекса атомарно
        std::lock_guard<std::mutex> lock1(mtx, std::adopt_lock);
        std::lock_guard<std::mutex> lock2(to.mtx, std::adopt_lock);
        
        balance -= amount;
        to.balance += amount;
    }
};
```

### 3. Условные переменные (Condition Variables)

Условные переменные - это механизм синхронизации, который позволяет потокам ожидать выполнения определенных условий. Они являются мощным инструментом для координации работы между потоками.

##### Основные концепции условных переменных

### 1. std::condition_variable

Класс из стандартной библиотеки C++, который предоставляет механизм ожидания уведомления.

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <queue>

std::mutex mtx;
std::condition_variable cv;
std::queue<int> data_queue;
bool finished = false;

// Поток-производитель
void producer() {
    for (int i = 0; i < 5; ++i) {
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
        {
            std::lock_guard<std::mutex> lock(mtx);
            data_queue.push(i);
            std::cout << "Произведено: " << i << std::endl;
        }
        cv.notify_one(); // Уведомляем один ожидающий поток
    }
    {
        std::lock_guard<std::mutex> lock(mtx);
        finished = true;
    }
    cv.notify_all(); // Уведомляем все ожидающие потоки
}

// Поток-потребитель
void consumer() {
    while (true) {
        std::unique_lock<std::mutex> lock(mtx);
        // Ожидаем, пока не появится данные или не завершится производство
        cv.wait(lock, []{ 
            return !data_queue.empty() || finished; 
        });
        
        if (finished && data_queue.empty()) break;
        
        while (!data_queue.empty()) {
            int val = data_queue.front();
            data_queue.pop();
            std::cout << "Потреблено: " << val << std::endl;
        }
    }
}

int main() {
    std::thread t1(producer);
    std::thread t2(consumer);
    
    t1.join();
    t2.join();
    
    return 0;
}
```

##### 2. Как работает condition_variable

1. **wait()**: 
   - Автоматически освобождает мьютекс и блокирует поток
   - Пробуждается при вызове notify_one() или notify_all()
   - Перед возвратом управления снова захватывает мьютекс

2. **notify_one()**: Пробуждает один из ожидающих потоков

3. **notify_all()**: Пробуждает все ожидающие потоки

##### 3. Шаблон "Ожидание с предикатом"

Рекомендуемый способ использования - с предикатом (лямбда-функцией):

```cpp
cv.wait(lock, []{ return condition; });
```

Эквивалентно:
```cpp
while (!condition) {
    cv.wait(lock);
}
```

##### Продвинутые техники работы с условными переменными

###### 1. Ожидание с таймаутом

```cpp
std::cv_status status;
do {
    status = cv.wait_for(lock, std::chrono::milliseconds(500));
    // Проверяем условие после таймаута
} while (status == std::cv_status::timeout && !condition);
```

###### 2. Множественные потребители

```cpp
void consumer(int id) {
    while (true) {
        std::unique_lock<std::mutex> lock(mtx);
        cv.wait(lock, []{ return !data_queue.empty() || finished; });
        
        if (finished && data_queue.empty()) break;
        
        if (!data_queue.empty()) {
            int val = data_queue.front();
            data_queue.pop();
            std::cout << "Потребитель " << id << " получил: " << val << std::endl;
        }
    }
}

int main() {
    std::thread producer_thread(producer);
    std::thread consumer_thread1(consumer, 1);
    std::thread consumer_thread2(consumer, 2);
    
    producer_thread.join();
    consumer_thread1.join();
    consumer_thread2.join();
    
    return 0;
}
```

###### 3. Очередь с ограниченным размером (bounded buffer)

```cpp
const int BUFFER_SIZE = 5;

void producer() {
    for (int i = 0; i < 10; ++i) {
        std::unique_lock<std::mutex> lock(mtx);
        // Ждем, пока не освободится место в буфере
        cv_producer.wait(lock, []{ return data_queue.size() < BUFFER_SIZE; });
        
        data_queue.push(i);
        std::cout << "Произведено: " << i << std::endl;
        
        lock.unlock();
        cv_consumer.notify_one();
    }
    {
        std::lock_guard<std::mutex> lock(mtx);
        finished = true;
    }
    cv_consumer.notify_all();
}
```

##### Распространенные проблемы и их решение

###### 1. Ложные пробуждения (spurious wakeups)

Условные переменные могут иногда пробуждаться без явного уведомления. Всегда используйте проверку условия:

```cpp
// Неправильно - возможна ошибка из-за ложного пробуждения
cv.wait(lock);

// Правильно - с проверкой условия
cv.wait(lock, []{ return condition; });
```

###### 3. Взаимоблокировки

Убедитесь, что все потоки используют одинаковый порядок блокировки мьютексов.

## Лучшие практики

1. Всегда защищайте общие данные мьютексом
2. Используйте unique_lock с condition_variable (не lock_guard)
3. Проверяйте условия в цикле или с предикатом
4. Избегайте уведомлений без изменения условий
5. Документируйте инварианты, связанные с условиями

###### Альтернативы std::condition_variable

В C++20 появились более простые альтернативы:

### 1. std::atomic::wait (C++20)

```cpp
std::atomic<bool> ready{false};

// Поток-ожидающий
while (!ready) {
    ready.wait(false);
}

// Поток-уведомляющий
ready = true;
ready.notify_one();
```

### 2. Семафоры (C++20)

```cpp
#include <semaphore>

std::counting_semaphore<10> sem(0);

// Поток-ожидающий
sem.acquire();

// Поток-уведомляющий
sem.release();
```

Условные переменные остаются мощным инструментом для сложных сценариев синхронизации, особенно когда необходимо ожидать выполнения составных условий.


### 4. Атомарные операции (Atomic Operations)

Операции, которые выполняются как единое целое без вмешательства других потоков.

```cpp
#include <iostream>
#include <thread>
#include <atomic>
#include <vector>

std::atomic<int> counter(0); // Атомарная переменная

void increment(int n) {
    for (int i = 0; i < n; ++i) {
        ++counter; // Атомарная операция
    }
}

int main() {
    std::thread t1(increment, 100000);
    std::thread t2(increment, 100000);
    
    t1.join();
    t2.join();
    
    std::cout << "Результат: " << counter << std::endl;
    // Всегда 200000, так как операции атомарные
    return 0;
}
```

Атомарные операции — это операции, которые выполняются **целиком и без вмешательства других потоков**. Они гарантируют, что никакие два потока не смогут одновременно модифицировать одну и ту же переменную, что предотвращает **состояния гонки (race conditions)**.

##### 1. Зачем нужны атомарные операции?
- **Без блокировок (lock-free)**: Атомарные операции позволяют избежать использования мьютексов, что повышает производительность.
- **Гарантия целостности данных**: Операция либо выполняется полностью, либо не выполняется вовсе.
- **Эффективность на уровне процессора**: Современные CPU поддерживают атомарные инструкции (например, `CAS` — Compare-And-Swap).

##### 2. Атомарные типы в C++
В C++11 появился заголовочный файл `<atomic>`, который предоставляет шаблонный класс `std::atomic<T>`.

###### 2.1. Основные атомарные типы
```cpp
#include <atomic>

std::atomic<int> counter(0);       // Атомарный int
std::atomic<bool> flag(false);     // Атомарный bool
std::atomic<double> value(3.14);   // Атомарный double (не на всех платформах)
```

###### 2.2. Пример использования
```cpp
#include <iostream>
#include <thread>
#include <atomic>

std::atomic<int> counter(0);

void increment() {
    for (int i = 0; i < 100'000; ++i) {
        counter.fetch_add(1);  // Атомарное увеличение на 1
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);

    t1.join();
    t2.join();

    std::cout << "Counter: " << counter << std::endl;  // Гарантированно 200'000
    return 0;
}
```


##### 3. Основные атомарные операции
###### 3.1. Чтение и запись
```cpp
std::atomic<int> x(0);

x.store(42);                // Атомарная запись
int val = x.load();          // Атомарное чтение
x = 10;                      // Эквивалентно x.store(10)
int y = x;                   // Эквивалентно y = x.load()
```

###### 3.2. Арифметические операции
```cpp
std::atomic<int> a(0);

a.fetch_add(5);    // Атомарное a += 5 (возвращает старое значение)
a.fetch_sub(3);    // Атомарное a -= 3
a++;               // Эквивалентно fetch_add(1)
++a;               // Тоже атомарно
```

###### 3.3. Битовая манипуляция (для integral типов)
```cpp
std::atomic<int> bits(0);

bits.fetch_and(0xF0);   // Атомарное AND
bits.fetch_or(0x0F);    // Атомарное OR
bits.fetch_xor(0xFF);   // Атомарное XOR
```

###### 3.4. Compare-And-Swap (CAS)
**CAS** — это фундаментальная операция для lock-free структур данных.
```cpp
std::atomic<int> val(10);

int expected = 10;
bool success = val.compare_exchange_strong(expected, 20);
// Если val == expected, то val = 20 и success = true
// Иначе expected = текущее значение val, success = false
```

##### 4. Модели памяти (Memory Order)
Атомарные операции могут иметь разную **упорядоченность** выполнения. Это важно для оптимизации.

##### 4.1. Основные модели памяти
1. **`memory_order_relaxed`**  
   Нет гарантий порядка операций. Только атомарность.
   ```cpp
   counter.fetch_add(1, std::memory_order_relaxed);
   ```
2. **`memory_order_acquire`**  
   Гарантирует, что все операции **после** атомарной не будут переупорядочены **до** неё.
3. **`memory_order_release`**  
   Гарантирует, что все операции **до** атомарной не будут переупорядочены **после** неё.
4. **`memory_order_seq_cst`** (по умолчанию)  
   Полная последовательная согласованность (самая строгая, но медленная).

##### 4.2. Пример Release-Acquire
```cpp
std::atomic<bool> ready(false);
int data = 0;

// Поток 1 (записывает данные)
data = 42;
ready.store(true, std::memory_order_release);  // Гарантирует, что data = 42 до ready = true

// Поток 2 (читает данные)
while (!ready.load(std::memory_order_acquire));  // Ждем ready = true
std::cout << data;  // Гарантированно увидит 42
```


### 5. Future и Promise

Механизмы для получения результата из асинхронных операций.

#### 1. Концептуальная модель "Обещание-Будущее"

Представьте ситуацию:
- **Профессор Promise** даёт задание ассистенту
- **Ассистент Future** возвращает результат, когда он будет готов

```cpp
#include <future>

std::promise<int> task_promise;  // Обещание предоставить результат
std::future<int> task_future = task_promise.get_future();  // Будущий результат
```

---

#### 2. Базовый пример: передача значения между потоками

```cpp
void compute(std::promise<int>&& prom) {
    // Долгие вычисления...
    int result = 42 * 42;
    prom.set_value(result);  // Выполняем обещание
}

int main() {
    std::promise<int> prom;
    std::future<int> fut = prom.get_future();
    
    std::thread worker(compute, std::move(prom));
    
    // Блокируемся, пока не получим результат
    std::cout << "Результат: " << fut.get() << std::endl;
    
    worker.join();
}
```
**Ключевые моменты:**
- `promise` — канал для записи результата
- `future` — канал для чтения результата
- `get()` блокирует поток до готовности результата

---

#### 3. Исключения в асинхронных задачах

Что если вычисление бросит исключение?
```cpp
void risky_computation(std::promise<int>&& prom) {
    try {
        throw std::runtime_error("Ошибка в вычислениях!");
        prom.set_value(42);
    } catch (...) {
        prom.set_exception(std::current_exception());
    }
}

int main() {
    std::promise<int> prom;
    auto fut = prom.get_future();
    
    std::thread t(risky_computation, std::move(prom));
    
    try {
        std::cout << fut.get() << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "Ошибка: " << e.what() << std::endl;
    }
    
    t.join();
}
```
**Важно:** исключение передаётся через `future::get()`

---

#### 4. std::async — высокоуровневая абстракция

Не хотите управлять потоками вручную? Используйте `async`!

```cpp
#include <future>

int compute() {
    std::this_thread::sleep_for(1s);
    return 42;
}

int main() {
    // Запускаем асинхронно (может выполняться в отдельном потоке)
    std::future<int> fut = std::async(std::launch::async, compute);
    
    // Делаем другую работу...
    
    // Получаем результат (блокируемся, если не готов)
    std::cout << "Результат: " << fut.get() << std::endl;
}
```

---

#### 5. Совместное использование future (std::shared_future)

Когда результат нужен нескольким потребителям:
```cpp
std::promise<int> prom;
std::shared_future<int> shared_fut = prom.get_future().share();

auto reader = [](std::shared_future<int> f) {
    std::cout << "Поток " << std::this_thread::get_id() 
              << " получил " << f.get() << std::endl;
};

prom.set_value(42);  // Записываем значение

std::thread t1(reader, shared_fut);
std::thread t2(reader, shared_fut);

t1.join(); t2.join();
```
**Особенность:** можно вызывать `get()` многократно

---

#### 6. Ожидание результата с таймаутом

```cpp
std::future<int> fut = std::async(compute);

// Ждём максимум 500ms
if (fut.wait_for(500ms) == std::future_status::ready) {
    std::cout << "Результат: " << fut.get() << std::endl;
} else {
    std::cout << "Вычисление не завершено!" << std::endl;
}
```
**Статусы ожидания:**
- `future_status::ready` — результат готов
- `future_status::timeout` — время вышло
- `future_status::deferred` — отложенное выполнение

---

#### 7. Практическое применение: параллельная обработка данных

```cpp
std::vector<int> process_chunk(const std::vector<int>& data) {
    // Тяжёлые вычисления...
    return transformed_data;
}

std::vector<int> parallel_process(const std::vector<int>& input) {
    auto mid = input.begin() + input.size()/2;
    
    // Запускаем обработку половинок данных параллельно
    auto fut1 = std::async(std::launch::async, process_chunk, 
                          std::vector<int>(input.begin(), mid));
    auto fut2 = std::async(std::launch::async, process_chunk,
                          std::vector<int>(mid, input.end()));
    
    // Получаем результаты
    auto part1 = fut1.get();
    auto part2 = fut2.get();
    
    // Объединяем
    part1.insert(part1.end(), part2.begin(), part2.end());
    return part1;
}
```


```cpp
#include <iostream>
#include <future>
#include <chrono>

// Функция, которая будет выполняться асинхронно
int long_running_task(int x) {
    std::this_thread::sleep_for(std::chrono::seconds(2));
    return x * x;
}

int main() {
    // Запускаем задачу асинхронно
    std::future<int> future_result = std::async(std::launch::async, long_running_task, 5);
    
    std::cout << "Ожидаем результат...\n";
    
    // Блокируемся до получения результата
    int result = future_result.get();
    
    std::cout << "Результат: " << result << std::endl;
    return 0;
}
```

### 6. Пакетные асинхронные задачи (std::async)

```cpp
#include <iostream>
#include <future>
#include <vector>

int compute(int x) {
    return x * x;
}

int main() {
    std::vector<std::future<int>> futures;
    
    // Запускаем несколько асинхронных задач
    for (int i = 0; i < 10; ++i) {
        futures.push_back(std::async(std::launch::async, compute, i));
    }
    
    // Получаем результаты
    for (auto& fut : futures) {
        std::cout << fut.get() << std::endl;
    }
    
    return 0;
}
```

### 7. Thread Local Storage (TLS)

Переменные, уникальные для каждого потока.

```cpp
#include <iostream>
#include <thread>

thread_local int thread_specific_var = 0; // Уникальна для каждого потока

void thread_function(int id) {
    thread_specific_var = id;
    std::cout << "Поток " << id << ": " << thread_specific_var << std::endl;
}

int main() {
    std::thread t1(thread_function, 1);
    std::thread t2(thread_function, 2);
    
    t1.join();
    t2.join();
    
    // В основном потоке переменная осталась 0
    std::cout << "Основной поток: " << thread_specific_var << std::endl;
    return 0;
}
```

### 8. Пул потоков (Thread Pool)

Шаблон для эффективного управления множеством задач.

```cpp
#include <iostream>
#include <vector>
#include <queue>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <functional>
#include <future>

// Класс пула потоков
class ThreadPool {
public:
    // Конструктор создает указанное количество потоков
    ThreadPool(size_t threads) : stop(false) {
        for(size_t i = 0; i < threads; ++i) {
            // Создаем рабочие потоки
            workers.emplace_back([this] {
                // Бесконечный цикл выполнения задач
                while(true) {
                    std::function<void()> task;  // Объект для хранения задачи
                    
                    {
                        // Блокируем мьютекс для доступа к очереди задач
                        std::unique_lock<std::mutex> lock(this->queue_mutex);
                        
                        // Ожидаем, пока появится задача или будет сигнал остановки
                        this->condition.wait(lock,
                            [this]{ return this->stop || !this->tasks.empty(); });
                            
                        // Если остановка и очередь пуста - завершаем поток
                        if(this->stop && this->tasks.empty())
                            return;
                            
                        // Берем задачу из очереди
                        task = std::move(this->tasks.front());
                        this->tasks.pop();
                    }
                    
                    // Выполняем задачу (мьютекс уже разблокирован)
                    task();
                }
            });
        }
    }
    
    // Метод для добавления задачи в пул
    template<class F, class... Args>
    auto enqueue(F&& f, Args&&... args) 
        -> std::future<typename std::result_of<F(Args...)>::type> {
        // Определяем тип возвращаемого значения функции
        using return_type = typename std::result_of<F(Args...)>::type;
        
        // Создаем packaged_task для функции, чтобы можно было получить future
        auto task = std::make_shared<std::packaged_task<return_type()>>(
            // Связываем функцию с аргументами
            std::bind(std::forward<F>(f), std::forward<Args>(args)...)
        );
        
        // Получаем future для результата задачи
        std::future<return_type> res = task->get_future();
        
        {
            // Блокируем мьютекс для добавления задачи в очередь
            std::unique_lock<std::mutex> lock(queue_mutex);
            
            // Проверяем, не остановлен ли пул
            if(stop)
                throw std::runtime_error("enqueue on stopped ThreadPool");
                
            // Добавляем задачу в очередь (лямбда, которая выполняет packaged_task)
            tasks.emplace([task](){ (*task)(); });
        }
        
        // Уведомляем один из ожидающих потоков о новой задаче
        condition.notify_one();
        
        // Возвращаем future, через который можно получить результат
        return res;
    }
    
    // Деструктор останавливает все потоки
    ~ThreadPool() {
        {
            // Блокируем мьютекс для установки флага остановки
            std::unique_lock<std::mutex> lock(queue_mutex);
            stop = true;
        }
        
        // Уведомляем все потоки о необходимости завершиться
        condition.notify_all();
        
        // Дожидаемся завершения всех рабочих потоков
        for(std::thread &worker: workers)
            worker.join();
    }
    
private:
    std::vector<std::thread> workers;  // Вектор рабочих потоков
    std::queue<std::function<void()>> tasks;  // Очередь задач
    
    std::mutex queue_mutex;  // Мьютекс для синхронизации доступа к очереди
    std::condition_variable condition;  // Условная переменная для ожидания задач
    bool stop;  // Флаг остановки пула
};

int main() {
    // Создаем пул из 4 потоков
    ThreadPool pool(4);
    std::vector<std::future<int>> results;  // Вектор для хранения результатов
    
    // Добавляем 8 задач в пул
    for(int i = 0; i < 8; ++i) {
        results.emplace_back(
            pool.enqueue([i] {
                std::cout << "Задача " << i << " выполняется\n";
                std::this_thread::sleep_for(std::chrono::seconds(1));
                return i*i;
            })
        );
    }
    
    // Ожидаем результаты всех задач
    for(auto && result: results)
        std::cout << "Результат: " << result.get() << std::endl;
    
    return 0;
}
```

## Заключение

Многопоточное программирование в C++ предоставляет богатый набор инструментов для создания параллельных и асинхронных приложений. Основные компоненты включают:

1. Потоки (std::thread) - базовый механизм параллельного выполнения
2. Синхронизация (мьютексы, условные переменные) - для безопасного доступа к общим данным
3. Атомарные операции - для lock-free программирования
4. Future/Promise - для асинхронных вычислений с возвращаемыми значениями
5. Thread Local Storage - для переменных, уникальных в каждом потоке
6. Пул потоков - для эффективного управления множеством задач

При разработке многопоточных приложений важно учитывать проблемы гонки данных, взаимоблокировки (deadlocks) и эффективное использование ресурсов процессора.
